---
layout: post
title: LASSO v.s. Ridge Regression -- L1 v.s. L2 norm
---
<!--
如何在github上的md file放入數學式：https://www.youtube.com/watch?v=dpVnmxpVdvg
在latex線上編輯器(http://latex.codecogs.com/eqneditor/editor.php)中輸入數學式，複製圖片網址，然後貼到以下![name](address)即可顯示數學式圖片
例如：![l2 nrom](https://latex.codecogs.com/svg.latex?\Large&space;\left\|\beta\right\|^{2}_{2})
或直接輸入latex數學代碼於 “ https://latex.codecogs.com/svg.latex?\Large&space; ” 後
例如：<img src="https://latex.codecogs.com/svg.latex?\Large&space;x=\frac{-b\pm\sqrt{b^2-4ac}}{2a}" title="\Large x=\frac{-b\pm\sqrt{b^2-4ac}}{2a}" />
-->
## 起源 
### 為什麼會有LASSO或Ridge Regression？

線性迴歸(Linear Regression)分析的目的，是找到一個符合特徵資料趨勢的線性模型。（注意：這裡的線性，是指對參數而言函數為線性，也就是係數的線性函數。）
<!-- more -->    

線性迴歸最常使用最小平方法來找出最小化「誤差平方和」的參數以做為參數的解(least squares estimate)。最小平方法的解空間幾乎沒有限制，因此人們試圖給予整個解空間一些限制，才有了以 L<sup>1</sup>-norm 限制解空間的 LASSO Regression ，和 L<sup>2</sup>-norm 限制解空間的 Ridge Regression。這些方法又稱L<sup>1</sup>-norm/L<sup>2</sup>-norm penalty/regularization。

<br>

### 什麼是Norm?

Mathematically a norm is a total size or length of all vectors in a vector space  or matrices.

定義上，令一個向量

![vector x](https://latex.codecogs.com/gif.latex?x%3D%20%5Cbegin%7Bbmatrix%7D%20x_1%5C%5C%20x_2%5C%5C%20%5Cvdots%20%5C%5C%20x_n%20%5Cend%7Bbmatrix%7D)

則

L<sup>1</sup>-norm 為

![l1 nrom](https://latex.codecogs.com/svg.latex?\Large&space;x=\sum{|x_{i}|}=|\beta|)

L<sup>2</sup>-norm 為

![l2 nrom](https://latex.codecogs.com/svg.latex?\Large&space;x=\sqrt{\sum{x_{i}^{2}}}=\left\|\beta\right\|^{2}_{2})

<br>

## 技術
令

![linear model](https://latex.codecogs.com/svg.latex?\Large&space;y=\beta_{0}+\beta_{1}x_{1}+...+\beta_{n}x_{n}=X\beta)
![X](https://latex.codecogs.com/svg.latex?\Large&space;X=\[1,x_{1},...,x_{n}\])
![beta](https://latex.codecogs.com/gif.latex?%5Cbeta%3D%20%5Cbegin%7Bbmatrix%7D%20%5Cbeta_0%5C%5C%20%5Cbeta_1%5C%5C%20%5Cvdots%5C%5C%20%5Cbeta_n%20%5Cend%7Bbmatrix%7D)
![bet](https://latex.codecogs.com/svg.latex?\Large&space;\beta=\[\beta_0&&\beta_1&&\vdots&&\beta_n\])

### L1 norm 跟 L2 norm的差別

### L<sup>1</sup>-norm Penalty/Regularization


### L<sup>2</sup>-norm Penalty/Regularization

<br>

## 特色

|        |   優點  |  缺點   |
| ------ | ------- | ------ |
|L1 norm |  sparse |        |
|L2 norm |         |        |

<br>

## 應用

### feature selection

### 解決/避免 overfitting
